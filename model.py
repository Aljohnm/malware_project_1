import pandas as pd
from sklearn.ensemble import RandomForestClassifier, StackingClassifier
from catboost import CatBoostClassifier
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report
import joblib
import json

# Load the dataset
data = pd.read_csv('malware_train_data.csv')

# Identify numerical and categorical features
numerical_features = [
    'File Size (KB)', 'Memory Usage (MB)', 'Battery Usage (%)', 'CPU Usage (%)',
    'Network Traffic (KB/s)', 'Process Count', 'Thread Count', 'I/O Read Rate (MB/s)',
    'I/O Write Rate (MB/s)', 'File Creation Time (Days ago)', 'Last Access Time (Days ago)',
    'File Entropy', 'System Calls per Second', 'Registry Changes Count', 'File Modifications Count',
    'Error Log Count', 'Warning Log Count'
]

categorical_features = [
    'Source IP', 'Destination IP', 'Protocol', 'Admin Privileges Used', 'File Write Permissions'
]

# Encode the target variable
label_encoder = LabelEncoder()
data['Malware Type'] = label_encoder.fit_transform(data['Malware Type'])  # Encode target labels

# Define features (all except the target 'Malware Type') and target
X = data[numerical_features + categorical_features]  # Features
y = data['Malware Type']  # Target variable

# Split the data into training and test sets (70% train, 30% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Preprocessing for numerical features
numeric_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())  # Standardize numerical features
])

# Preprocessing for categorical features
categorical_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode categorical features
])

# Define the column transformer for both numerical and categorical features
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numerical_features),
        ('cat', categorical_transformer, categorical_features)
    ])

# Define models for stacking
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
catboost_model = CatBoostClassifier(verbose=0)

# Create a Stacking Classifier with RandomForest as the final estimator
stacked_model = StackingClassifier(
    estimators=[('rf', rf_model), ('catboost', catboost_model)],
    final_estimator=RandomForestClassifier(random_state=42)
)

# Create a pipeline with preprocessing and the model
pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', stacked_model)])

# Train the model
pipeline.fit(X_train, y_train)

# Save the trained pipeline to a file for later use
joblib.dump(pipeline, 'trained_pipeline.pkl')

# Also save the LabelEncoder for future label decoding
joblib.dump(label_encoder, 'label_encoder.pkl')

# Test the model on the test set
y_pred = pipeline.predict(X_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)

# Generate classification report with original labels
report = classification_report(
    y_test,
    y_pred,
    target_names=label_encoder.inverse_transform(range(len(label_encoder.classes_))),
    output_dict=True  # output as a dict to be formatted into JSON
)

# Prepare the result for printing in a structured format
result = {
    "accuracy": accuracy,
    "classification_report": report,
    "predictions": label_encoder.inverse_transform(y_pred).tolist()  # Convert predictions back to original labels
}

# Print the results as JSON (formatted for better readability)
print(json.dumps(result, indent=4))

# Save classification report and accuracy to a JSON file
with open('classification_report.json', 'w') as report_file:
    json.dump(result, report_file, indent=4)
# Function to load models for FastAPI app
def load_models():
    # Load the trained pipeline
    pipeline = joblib.load('trained_pipeline.pkl')
    
    # Load the LabelEncoder for label decoding
    label_encoder = joblib.load('label_encoder.pkl')
    
    return pipeline, label_encoder